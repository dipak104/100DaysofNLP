{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_RNN_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKjqgVW9oXGr"
      },
      "source": [
        "#!pip install torch==1.6.0 torchvision==0.7.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDDQeF61LFG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44d94fe-9465-47c7-85b1-821d660e1ba5"
      },
      "source": [
        "import torch\r\n",
        "print(torch.__version__)\r\n",
        "from torchtext import data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDx66-BPLIWK"
      },
      "source": [
        "SEED = 1111\r\n",
        "torch.manual_seed(SEED)\r\n",
        "TEXT = data.Field(tokenize='spacy', include_lengths=True) # If spacy not passed then it will split the text on the basis of spaces.\r\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQCsrAd7Hks6"
      },
      "source": [
        "Downloading IMDB dataset from torchtext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOVfb5TDLXJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884421cc-2153-4009-c644-8820fd632820"
      },
      "source": [
        "%%time\r\n",
        "from torchtext import datasets\r\n",
        "\r\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   0%|          | 164k/84.1M [00:00<00:59, 1.42MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 73.6MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 18s, sys: 8.46 s, total: 1min 26s\n",
            "Wall time: 1min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tqI9I7WL9fd",
        "outputId": "53e41d08-aa25-46ad-fb93-c2c1bd0d9a4d"
      },
      "source": [
        "len(train), len(test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzptyFyQMGYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791f5df5-a33f-446f-969e-43da9eb82749"
      },
      "source": [
        "print(vars(train.examples[0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['This', 'is', 'an', 'awesome', 'classic', 'monster', 'flick', 'from', 'the', '50', \"'s\", '!', 'I', 'just', 'love', 'the', 'look', 'of', 'the', '50', \"'s\", 'in', 'general', 'like', 'the', 'cars', 'and', 'the', 'music', '.', 'Anyway', ',', 'I', 'love', 'the', 'way', 'the', 'blob', 'looks', '.', 'I', 'love', 'when', 'the', 'everyone', 'is', 'at', 'the', 'late', 'night', 'horror', 'flick', 'at', 'the', 'theater', 'and', 'the', 'blob', 'comes', 'in', 'and', 'crashes', 'the', 'party', '.', 'Another', 'thing', 'I', 'love', 'about', 'it', 'is', 'that', 'it', 'takes', 'place', 'all', 'in', 'one', 'night', ',', 'just', 'like', 'Halloween', 'II.<br', '/><br', '/>When', 'Steve', 'and', 'Jane', 'are', 'making', 'out', ',', 'they', 'see', 'a', 'meteor', 'fall', 'from', 'space', '.', 'Inside', 'the', 'meteor', 'is', 'the', 'blob', '.', 'Whenever', 'the', 'blob', 'consumes', 'a', 'person', ',', 'it', 'grows', 'bigger', 'and', 'bigger', '.', 'They', 'try', 'to', 'convince', 'the', 'people', 'of', 'the', 'town', 'about', 'the', 'blobby', 'monster', ',', 'but', 'no', 'one', 'believes', 'them', 'until', 'later', '.', 'Can', 'anything', 'stop', 'this', 'blobby', 'creature', '?', 'I', 'highly', 'recommend', 'THE', 'BLOB', '!', '!', '!'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRrfdpQRD7KY"
      },
      "source": [
        "# We only have train and test data in IMDB dataset\r\n",
        "Let's create validation data out of train data\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApFt0Gl8NJg7"
      },
      "source": [
        "# The following code automatically downloads the IMDb dataset and splits it into the \r\n",
        "# canonical train/test splits as torchtext.datasets objects.\r\n",
        "import random\r\n",
        "train, valid = train.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqLBPUDSVTuK"
      },
      "source": [
        "Download the word embeddings - \"glove.6B.100d\". The reason to use pre_trained word embeddings is they are initialized with pre-trained vectors. These pre-trained vectors already have words with similar semantic meaning close together in vector space. This gives our embeding layer a good initialization as it doen not have to learn these relations from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckjV8vtrdQs6"
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eW5PTVWe27a"
      },
      "source": [
        "#!unzip '/content/glove.6B.zip'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asVRDNkkgZx7"
      },
      "source": [
        "#import torchtext.vocab as vocab"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9PpzRouhsHU"
      },
      "source": [
        "#glove = vocab.GloVe(name='6B', dim=100)\r\n",
        "#print('Loaded {} words'.format(len(glove.itos)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbkwmQNoNf9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332bf66c-1c70-4373-c49b-89537c8d5fda"
      },
      "source": [
        "# We have to build a vocabulary. A look up table where every unique word is mapped to a integer\r\n",
        "MAX_VOCAB_SIZE = 25_000\r\n",
        "\r\n",
        "TEXT.build_vocab(train, \r\n",
        "                 max_size=MAX_VOCAB_SIZE,\r\n",
        "                 vectors = \"glove.6B.100d\",\r\n",
        "                 unk_init = torch.Tensor.normal_)\r\n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                          \n",
            "100%|█████████▉| 399098/400000 [00:15<00:00, 26174.48it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0_cFqINqFn",
        "outputId": "8f97ddfb-b2ba-4ea7-a091-e43d4a54bc3b"
      },
      "source": [
        "len(TEXT.vocab), len(LABEL.vocab)\r\n",
        "# The two additional tokens in TEXT.vocab is <unk>, <pad>"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25002, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyCBB6TZFJBr"
      },
      "source": [
        "#vars(TEXT.vocab)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGaiTpRdSG9z",
        "outputId": "e6814a5e-d094-4cf6-aeca-0576a2ec4dc2"
      },
      "source": [
        "vars(LABEL.vocab)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'neg': 8726, 'pos': 8774}),\n",
              " 'itos': ['pos', 'neg'],\n",
              " 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "             {'neg': 1, 'pos': 0}),\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6ybxvzGN7Es",
        "outputId": "f10480af-ce16-4f15-fa8e-c7da8d2cb085"
      },
      "source": [
        "# Most common words in the voabulary with frequencies\r\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 202592),\n",
              " (',', 192270),\n",
              " ('.', 165440),\n",
              " ('a', 109087),\n",
              " ('and', 108859),\n",
              " ('of', 100816),\n",
              " ('to', 93674),\n",
              " ('is', 76066),\n",
              " ('in', 61473),\n",
              " ('I', 53943)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbRBMvOjOCnV",
        "outputId": "d5294b74-5dad-4b1d-dca4-49578ea18eb9"
      },
      "source": [
        "# To check the vocabulary\r\n",
        "TEXT.vocab.itos[:10]     #itos - integer to string"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz4y74ACONu8",
        "outputId": "73b7dea2-7aa4-481d-cd80-fb4265aff31b"
      },
      "source": [
        "# Check the labels    # stor - string to integer\r\n",
        "LABEL.vocab.stoi"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "            {'neg': 1, 'pos': 0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PobDQaUTFcRr"
      },
      "source": [
        "Final step is to create the iterators.\r\n",
        "We'll use a BucketIterator which is a special type of\r\n",
        "iterator that will return a batch of examples where each\r\n",
        "example is of a similar length, minimizing the amount of \r\n",
        "padding per example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JMmcujqSgzf"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\r\n",
        "    (train, valid, test),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    sort_within_batch=True,\r\n",
        "    device = device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmokvekmS56y"
      },
      "source": [
        "# Build the RNN Model\r\n",
        "\r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwqSzWXfTDdk"
      },
      "source": [
        "class RNN(nn.Module):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\r\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional=bidirectional, dropout=dropout)\r\n",
        "    self.linear = nn.Linear(hidden_dim*2, output_dim)\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "  def forward(self, text, text_length):\r\n",
        "    embedded = self.dropout(self.embedding(text))\r\n",
        "    pack_embedding = nn.utils.rnn.pack_padded_sequence(embedded, text_length.cpu())\r\n",
        "    pack_output, (hidden, cell) = self.rnn(pack_embedding)\r\n",
        "    output, output_length = nn.utils.rnn.pad_packed_sequence(pack_output)\r\n",
        "    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\r\n",
        "    return self.linear(hidden)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2S8wgxQTh1I"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\r\n",
        "EMBEDDING_DIM = 100\r\n",
        "HIDDEN_DIM = 256\r\n",
        "OUTPUT_DIM = 1\r\n",
        "N_LAYERS = 2\r\n",
        "BIDIRECTIONAL = True\r\n",
        "DROPOUT = 0.5\r\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\r\n",
        "\r\n",
        "model = RNN(INPUT_DIM, \r\n",
        "            EMBEDDING_DIM, \r\n",
        "            HIDDEN_DIM, \r\n",
        "            OUTPUT_DIM,\r\n",
        "            N_LAYERS,\r\n",
        "            BIDIRECTIONAL,\r\n",
        "            DROPOUT,\r\n",
        "            PAD_IDX)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXzm7lGjjzs2",
        "outputId": "ed48eeea-3918-4a45-9e1e-8fab01b78625"
      },
      "source": [
        "embeddings = TEXT.vocab.vectors\r\n",
        "embeddings.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25002, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uce7P3Ojzc2",
        "outputId": "eed4f90f-0573-49bb-c356-ab91b108e559"
      },
      "source": [
        "model.embedding.weight.data.copy_(embeddings)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1065,  0.1614, -0.6850,  ..., -0.9348, -0.4778,  1.1286],\n",
              "        [ 0.2091,  0.2932,  0.3151,  ...,  1.1860, -1.5726,  1.1354],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.5523,  0.9965, -1.0090,  ..., -0.7429, -0.5860,  0.2106],\n",
              "        [-0.4512,  0.6889, -0.0336,  ..., -0.2433,  0.4338,  0.6551],\n",
              "        [ 0.7438,  1.1903, -0.4427,  ..., -0.2208,  0.5125,  0.4214]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-RHTZg4kDli"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\r\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\r\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZddQ01CkDi8",
        "outputId": "31b7b54d-1edc-422b-b1a3-1c3a07688b02"
      },
      "source": [
        "model.embedding.weight.data"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.5523,  0.9965, -1.0090,  ..., -0.7429, -0.5860,  0.2106],\n",
              "        [-0.4512,  0.6889, -0.0336,  ..., -0.2433,  0.4338,  0.6551],\n",
              "        [ 0.7438,  1.1903, -0.4427,  ..., -0.2208,  0.5125,  0.4214]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIc8TuIBT9Ht"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf42DTNkUbSS"
      },
      "source": [
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVbr5qV3U7gw"
      },
      "source": [
        "def model_accuracy(predictions, y):\r\n",
        "  pred = torch.round(torch.sigmoid(predictions))\r\n",
        "  actual = (pred == y).float()\r\n",
        "  acc = actual.sum() / len(actual)\r\n",
        "  return acc"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9exV3bc1UfZ5"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\r\n",
        "  epoch_loss = 0\r\n",
        "  epoch_acc = 0\r\n",
        "  model.train()\r\n",
        "  for batch in iterator:\r\n",
        "    optimizer.zero_grad()    # zero the gradients\r\n",
        "    #print(batch.text)\r\n",
        "    text, text_length = batch.text\r\n",
        "    #print(\"*\")\r\n",
        "    predictions = model(text, text_length).squeeze(1)\r\n",
        "    #print(\"*\")\r\n",
        "    loss = criterion(predictions, batch.label.float())   # Calculate the loss\r\n",
        "    acc = model_accuracy(predictions, batch.label)\r\n",
        "    loss.backward()  # calculate the gradient of each parameter with loss.backward()\r\n",
        "    optimizer.step() # update the parameters using the gradients and optimizer algorithm\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    epoch_acc += acc.item()\r\n",
        "        \r\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muzzBFN3Ghx6"
      },
      "source": [
        "In eval function we do not want to update the parameters when evaluating.\r\n",
        "So, we don't need optimizer.zero_grad(), loss.backward() and optimizer.step()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9m0sENfUlmL"
      },
      "source": [
        "def eval(model, iterator, criterion):\r\n",
        "  epoch_loss = 0\r\n",
        "  epoch_acc = 0\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  \"\"\"No gradients are calculated on PyTorch operations inside the with \r\n",
        "  no_grad() block. This causes less memory to be \r\n",
        "  used and speeds up computation\"\"\"\r\n",
        "  with torch.no_grad(): \r\n",
        "    for batch in iterator:\r\n",
        "      text, text_length = batch.text\r\n",
        "      predictions = model(text, text_length).squeeze(1)\r\n",
        "      loss = criterion(predictions, batch.label)\r\n",
        "      acc = model_accuracy(predictions, batch.label)\r\n",
        "\r\n",
        "      epoch_loss += loss.item()\r\n",
        "      epoch_acc += acc.item()\r\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)  "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpA6ixypWJPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f5280a-0cf4-43c2-86df-b2c25be58794"
      },
      "source": [
        "import time\r\n",
        "EPOCHS = 5\r\n",
        "opt_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start_time = time.time()\r\n",
        "  #print(start_time)\r\n",
        "  train_loss, train_acc = train(model, train_iter, optimizer, criterion)\r\n",
        "  print(\"*\")\r\n",
        "  valid_loss, valid_acc = eval(model, valid_iter, criterion)\r\n",
        "  print(\"*\")\r\n",
        "  end_time = time.time()\r\n",
        "  if valid_loss < opt_valid_loss:\r\n",
        "    opt_valid_loss = valid_loss\r\n",
        "    torch.save(model.state_dict(), 'LSTM-RNN-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1}')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399098/400000 [00:29<00:00, 26174.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*\n",
            "*\n",
            "Epoch: 1\n",
            "\tTrain Loss: 0.676 | Train Acc: 0.57%\n",
            "\t Val. Loss: 0.606 |  Val. Acc: 0.70%\n",
            "*\n",
            "*\n",
            "*\n",
            "*\n",
            "Epoch: 3\n",
            "\tTrain Loss: 0.518 | Train Acc: 0.75%\n",
            "\t Val. Loss: 0.383 |  Val. Acc: 0.83%\n",
            "*\n",
            "*\n",
            "Epoch: 4\n",
            "\tTrain Loss: 0.385 | Train Acc: 0.83%\n",
            "\t Val. Loss: 0.351 |  Val. Acc: 0.85%\n",
            "*\n",
            "*\n",
            "Epoch: 5\n",
            "\tTrain Loss: 0.297 | Train Acc: 0.88%\n",
            "\t Val. Loss: 0.285 |  Val. Acc: 0.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN542gsDHB1p"
      },
      "source": [
        "As we can see that the accuracy is poor. So, we need to improve the model by hypertuning it or to use different Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsP_n1egRXq-",
        "outputId": "fd7f20a6-f24e-477a-dcc7-cc23f1ba0b5a"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/LSTM-RNN-model.pt'))\r\n",
        "\r\n",
        "test_loss, test_acc = eval(model, test_iter, criterion)\r\n",
        "\r\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}%')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.304 | Test Acc: 0.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlwasmeDjPbO"
      },
      "source": [
        "import spacy\r\n",
        "nlp = spacy.load('en')\r\n",
        "\r\n",
        "def predict(model, text):\r\n",
        "  model.eval()\r\n",
        "  tokenize = [token.text for token in nlp.tokenizer(text)]\r\n",
        "  index = [TEXT.vocab.stoi[t] for t in tokenize]\r\n",
        "  length = [len(index)]\r\n",
        "  tensor = torch.LongTensor(index).to(device).unsqueeze(1)\r\n",
        "  len_tensor = torch.LongTensor(length)\r\n",
        "  pred = torch.sigmoid(model(tensor, len_tensor))\r\n",
        "  return pred.item()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9i396SHUuHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb16aa3d-f925-497f-f7ad-1ac2b1f99a50"
      },
      "source": [
        "predict(model, \"This person is bad\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99434894323349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doy1H1dtkD6c",
        "outputId": "1e1c3a86-fa7c-48c2-83f7-2cb6b7c72f6e"
      },
      "source": [
        "predict(model, \"I am lovable\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1871410459280014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr31IK5hktQb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}