{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cosine Similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4fiMjHoR07b"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import pandas as pd"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogXts4htQcdf"
      },
      "source": [
        "# Define the documents\r\n",
        "\r\n",
        "doc1 = \"Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin\"\r\n",
        "\r\n",
        "doc2 = \"President Trump says Putin had no political interference is the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election\"\r\n",
        "\r\n",
        "doc3 = \"Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career\"\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QaYxJxQRm0H"
      },
      "source": [
        "documents = [doc1, doc2, doc3]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "jBBzDyNaRsly",
        "outputId": "0a4a4307-37b5-4d8a-f626-ee25b7872811"
      },
      "source": [
        "# Create the Document Term Matrix\r\n",
        "\r\n",
        "tfidf = TfidfVectorizer(stop_words='english')\r\n",
        "sparse_matrix = tfidf.fit_transform(documents)\r\n",
        "\r\n",
        "doc_matrix = sparse_matrix.todense()\r\n",
        "df = pd.DataFrame(doc_matrix, columns = tfidf.get_feature_names(),\r\n",
        "                  index = ['doc1', 'doc2', 'doc3'])\r\n",
        "df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>career</th>\n",
              "      <th>claimed</th>\n",
              "      <th>earlier</th>\n",
              "      <th>election</th>\n",
              "      <th>elections</th>\n",
              "      <th>friend</th>\n",
              "      <th>friends</th>\n",
              "      <th>interference</th>\n",
              "      <th>lost</th>\n",
              "      <th>minister</th>\n",
              "      <th>mr</th>\n",
              "      <th>outcome</th>\n",
              "      <th>parties</th>\n",
              "      <th>political</th>\n",
              "      <th>post</th>\n",
              "      <th>president</th>\n",
              "      <th>prime</th>\n",
              "      <th>putin</th>\n",
              "      <th>republican</th>\n",
              "      <th>russia</th>\n",
              "      <th>says</th>\n",
              "      <th>served</th>\n",
              "      <th>support</th>\n",
              "      <th>trump</th>\n",
              "      <th>vladimir</th>\n",
              "      <th>winning</th>\n",
              "      <th>witchhunt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.203368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.53481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157934</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.315867</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157934</td>\n",
              "      <td>0.267405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267405</td>\n",
              "      <td>0.406737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267405</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.241982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.241982</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.241982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.241982</td>\n",
              "      <td>0.241982</td>\n",
              "      <td>0.285837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.483963</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.184033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.241982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc3</th>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.169514</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.339028</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.339028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        career   claimed   earlier  ...  vladimir   winning  witchhunt\n",
              "doc1  0.000000  0.000000  0.000000  ...  0.000000  0.267405   0.000000\n",
              "doc2  0.000000  0.241982  0.000000  ...  0.000000  0.000000   0.241982\n",
              "doc3  0.287012  0.000000  0.287012  ...  0.287012  0.000000   0.000000\n",
              "\n",
              "[3 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q9Caa4bSfv9",
        "outputId": "d7aed24b-3122-4b88-8ef5-e779a5c419e9"
      },
      "source": [
        "# Compute cosine similarity\r\n",
        "\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "print(cosine_similarity(df, df))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.33027897 0.18740386]\n",
            " [0.33027897 1.         0.24226661]\n",
            " [0.18740386 0.24226661 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BQ-8_0QS8UA"
      },
      "source": [
        "doc4 = \"Soup is a primarily liquid food, generally served warm or hot (but may be cool or cold), that is made by combining ingredients of meat or vegetables with stock, juice, water, or another liquid. \"\r\n",
        "\r\n",
        "doc5 = \"Noodles are a staple food in many cultures. They are made from unleavened dough which is stretched, extruded, or rolled flat and cut into one of a variety of shapes.\"\r\n",
        "\r\n",
        "doc6 = \"Dosa is a type of pancake from the Indian subcontinent, made from a fermented batter. It is somewhat similar to a crepe in appearance. Its main ingredients are rice and black gram.\"\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNwVgqC8TL8x"
      },
      "source": [
        "documents = [doc1, doc2, doc3, doc4, doc5, doc6]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFX-Klh4TZR_"
      },
      "source": [
        "Suppose if you have another set of documents on a completely different topic, say ‘food’, you want a similarity metric that gives higher scores for documents belonging to the same topic and lower scores when comparing docs from different topics.\r\n",
        "\r\n",
        "we need to consider the semantic meaning should be considered. That is, words similar in meaning should be treated as similar. \r\n",
        "\r\n",
        "For this, converting the words into respective word vectors, and then, computing the similarities can address this problem.\r\n",
        "\r\n",
        "SO,to get the word vectors we need a word embedding model.\r\n",
        "We can use FastText from Gensim."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsZGkKkhTQhU"
      },
      "source": [
        "import gensim\r\n",
        "from gensim.matutils import softcossim\r\n",
        "from gensim import corpora\r\n",
        "import gensim.downloader as api\r\n",
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UngjsFlbT1Dp",
        "outputId": "23cc79b5-cc88-40cd-fdca-7261d598769e"
      },
      "source": [
        "# Downlaod the fasttext model\r\n",
        "\r\n",
        "fasttext = api.load('fasttext-wiki-news-subwords-300')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.6% 954.2/958.4MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCBVYATmT-vo"
      },
      "source": [
        "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\r\n",
        "\r\n",
        "similarity_matrix = fasttext.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrdRfde6UXRu"
      },
      "source": [
        "sent1 = dictionary.doc2bow(simple_preprocess(doc1))\r\n",
        "sent2 = dictionary.doc2bow(simple_preprocess(doc2))\r\n",
        "sent3 = dictionary.doc2bow(simple_preprocess(doc3))\r\n",
        "sent4 = dictionary.doc2bow(simple_preprocess(doc4))\r\n",
        "sent5 = dictionary.doc2bow(simple_preprocess(doc5))\r\n",
        "sent6 = dictionary.doc2bow(simple_preprocess(doc6))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45LzG8xbUcoY"
      },
      "source": [
        "sentences = [sent1, sent2, sent3, sent4, sent5, sent6]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjJTPbxRUigY",
        "outputId": "6193e257-0abc-4e00-9691-4e4821b48021"
      },
      "source": [
        "print(softcossim(sent1, sent2, similarity_matrix))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5842470477718544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "65LA0wSzUp5_",
        "outputId": "cc6e4999-67e8-44df-e914-619258cee422"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "array_len = np.arange(len(sentences))\r\n",
        "xx, yy = np.meshgrid(array_len, array_len)\r\n",
        "cossim_mat = pd.DataFrame([[round(softcossim(sentences[i], sentences[j], similarity_matrix),2) for i , j in zip(x, y)] for y, x in zip(xx, yy)])\r\n",
        "cossim_mat"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.58</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.54</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     2     3     4     5\n",
              "0  1.00  0.58  0.56  0.28  0.34  0.40\n",
              "1  0.58  1.00  0.54  0.25  0.31  0.43\n",
              "2  0.56  0.54  1.00  0.19  0.25  0.36\n",
              "3  0.28  0.25  0.19  1.00  0.50  0.38\n",
              "4  0.34  0.31  0.25  0.50  1.00  0.56\n",
              "5  0.40  0.43  0.36  0.38  0.56  1.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWdl41GFVP9b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}