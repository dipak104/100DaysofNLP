{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDDQeF61LFG9"
      },
      "source": [
        "import torch\r\n",
        "from torchtext import data\r\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDx66-BPLIWK"
      },
      "source": [
        "SEED = 1111\r\n",
        "torch.manual_seed(SEED)\r\n",
        "TEXT = data.Field(tokenize='spacy') # If spacy not passed then it will split the text on the basis of spaces.\r\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQCsrAd7Hks6"
      },
      "source": [
        "Downloading IMDB dataset from torchtext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOVfb5TDLXJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fef4d9-fdf8-4661-a4ea-fa37fd4c600b"
      },
      "source": [
        "%%time\r\n",
        "from torchtext import datasets\r\n",
        "\r\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 10.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 45s, sys: 12.9 s, total: 1min 57s\n",
            "Wall time: 2min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tqI9I7WL9fd",
        "outputId": "fd1ea6da-ba99-45dc-fcbe-4eda0fb57e52"
      },
      "source": [
        "len(train), len(test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzptyFyQMGYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a0df76-1be9-4b59-90e9-0c2d8d267813"
      },
      "source": [
        "print(vars(train.examples[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['I', 'have', 'no', 'idea', 'how', 'IMDb', 'sorts', 'reviews', 'but', 'I', 'do', 'know', 'that', ',', 'as', 'happens', 'often', 'on', 'Amazon.com', ',', 'there', 'are', 'a', 'striking', 'number', 'of', 'very', 'negative', 'reviews', 'for', 'this', 'movie', 'which', 'repeat', 'the', 'same', ',', 'somewhat', 'obscure', 'talking', 'points', ',', 'almost', 'verbatim', '.', 'A', 'campaign', '?', 'Only', 'IMDb', 'knows.<br', '/><br', '/>As', 'for', 'this', 'movie', ':', 'it', \"'s\", 'fine', '.', 'It', \"'s\", 'a', 'funny', ',', 'cute', 'and', 'very', 'straightforward', 'movie.<br', '/><br', '/>It', \"'s\", 'been', 'over', 'a', 'decade', 'since', 'I', 'worked', 'in', 'Brooklyn', ',', 'lived', 'in', 'Queens', 'and', 'visited', 'relatives', 'in', 'the', 'South', 'Bronx', '.', 'But', 'I', 'found', 'nothing', 'inauthentic', 'or', 'exploitative', 'about', 'these', 'kids', '.', 'Is', 'the', 'grandmother', 'a', 'bizarre', 'character', '?', 'Yup', '.', 'Do', 'the', 'dialogue', 'and', 'plot', 'acknowledge', 'this', '?', 'Yes', ',', 'thankfully', ',', 'they', 'do', '.', 'Are', 'other', 'movies', 'set', 'in', 'the', 'LES', 'and', 'featuring', 'Dominican', '/', 'Puerto', 'Rican', 'kids', 'possible', '?', 'You', 'betcha', '.', 'Does', 'that', 'make', 'this', 'movie', 'a', 'crime', '\\x97', 'as', 'some', 'of', 'the', '(', 'to', 'my', 'eyes', ',', 'astroturf', ')', 'comments', 'would', 'suggest', '?', 'Hardly', '.', 'Let', 'a', 'thousand', 'plastic', 'flowers', 'bloom.<br', '/><br', '/>This', 'is', 'better', 'than', 'any', 'episode', 'of', 'Degrassi', 'JR', '.', 'High', 'or', 'Degrassi', 'High', '.', 'Scoff', 'at', 'the', 'comparison', 'but', '_', 'we', \"'ve\", 'never', 'had', 'that', '_', 'and', 'I', \"'m\", 'touched', ',', 'to', 'the', 'core', ',', 'by', 'this', 'movie', \"'s\", 'humility', 'of', 'purpose', 'and', 'tender', 'spirit.<br', '/><br', '/>That', 'said', ',', 'I', \"'d\", 'love', 'to', 'know', 'the', 'backstory', 'behind', 'all', 'this', 'backbiting', '!', ':-D'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRrfdpQRD7KY"
      },
      "source": [
        "# We only have train and test data in IMDB dataset\r\n",
        "Let's create validation data out of train data\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApFt0Gl8NJg7"
      },
      "source": [
        "# The following code automatically downloads the IMDb dataset and splits it into the \r\n",
        "# canonical train/test splits as torchtext.datasets objects.\r\n",
        "import random\r\n",
        "train, valid = train.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbkwmQNoNf9y"
      },
      "source": [
        "# We have to build a vocabulary. A look up table where every unique word is mapped to a integer\r\n",
        "MAX_VOCAB_SIZE = 25_000\r\n",
        "\r\n",
        "TEXT.build_vocab(train, max_size=MAX_VOCAB_SIZE)\r\n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0_cFqINqFn",
        "outputId": "a61afedf-b461-409c-eef5-3c8147d0252a"
      },
      "source": [
        "len(TEXT.vocab), len(LABEL.vocab)\r\n",
        "# The two additional tokens in TEXT.vocab is <unk>, <pad>"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25002, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGaiTpRdSG9z",
        "outputId": "6055ce78-7e7f-4db7-eead-e5efae0b2db8"
      },
      "source": [
        "vars(LABEL.vocab)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'freqs': Counter({'neg': 8726, 'pos': 8774}),\n",
              " 'itos': ['pos', 'neg'],\n",
              " 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "             {'neg': 1, 'pos': 0}),\n",
              " 'vectors': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6ybxvzGN7Es",
        "outputId": "84dcfead-df80-45d2-a016-65e46f5ebfa9"
      },
      "source": [
        "# Most common words in the voabulary with frequencies\r\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 202064),\n",
              " (',', 192632),\n",
              " ('.', 165386),\n",
              " ('and', 109129),\n",
              " ('a', 108943),\n",
              " ('of', 100049),\n",
              " ('to', 93051),\n",
              " ('is', 76037),\n",
              " ('in', 61344),\n",
              " ('I', 54271)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbRBMvOjOCnV",
        "outputId": "b0dc405b-159b-44e5-fc13-b55c8497bcef"
      },
      "source": [
        "# To check the vocabulary\r\n",
        "TEXT.vocab.itos[:10]     #itos - integer to string"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz4y74ACONu8",
        "outputId": "9e37c801-5756-48ec-e9ad-6ea6170fded9"
      },
      "source": [
        "# Check the labels    # stor - string to integer\r\n",
        "LABEL.vocab.stoi"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "            {'neg': 1, 'pos': 0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PobDQaUTFcRr"
      },
      "source": [
        "Final step is to create the iterators.\r\n",
        "We'll use a BucketIterator which is a special type of\r\n",
        "iterator that will return a batch of examples where each\r\n",
        "example is of a similar length, minimizing the amount of \r\n",
        "padding per example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JMmcujqSgzf"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\r\n",
        "    (train, valid, test),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    device = device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8_tuj5Msv21",
        "outputId": "5906cebf-7e21-4b32-e3f4-daa0539286c6"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDjz6eiubCRj",
        "outputId": "55d34dfe-d71a-4d2d-f3bd-3354afe68f72"
      },
      "source": [
        "train_iter"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.iterator.BucketIterator at 0x7f33697e94e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmokvekmS56y"
      },
      "source": [
        "# Build the RNN Model\r\n",
        "\r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwqSzWXfTDdk"
      },
      "source": [
        "class RNN(nn.Module):\r\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\r\n",
        "    self.rnn = nn.RNN(embedding_dim, hidden_dim)\r\n",
        "    self.linear = nn.Linear(hidden_dim, output_dim)\r\n",
        "  def forward(self, text):\r\n",
        "    embedded = self.embedding(text)\r\n",
        "    output, hidden = self.rnn(embedded)\r\n",
        "    assert torch.equal(output[-1, :, :], hidden.squeeze(0))\r\n",
        "    return self.linear(hidden.squeeze(0))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2S8wgxQTh1I"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\r\n",
        "EMBEDDING_DIM = 100\r\n",
        "HIDDEN_DIM = 256\r\n",
        "OUTPUT_DIM = 1\r\n",
        "\r\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIc8TuIBT9Ht"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "optimizer = optim.SGD(model.parameters(),lr=  1e-3)\r\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf42DTNkUbSS"
      },
      "source": [
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVbr5qV3U7gw"
      },
      "source": [
        "def model_accuracy(predictions, y):\r\n",
        "  pred = torch.round(torch.sigmoid(predictions))\r\n",
        "  actual = (pred == y).float()\r\n",
        "  acc = actual.sum() / len(actual)\r\n",
        "  return acc"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9exV3bc1UfZ5"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\r\n",
        "  epoch_loss = 0\r\n",
        "  epoch_acc = 0\r\n",
        "  model.train()\r\n",
        "  for i, batch in enumerate(iterator):\r\n",
        "    optimizer.zero_grad()    # zero the gradients\r\n",
        "    #print(batch.text)\r\n",
        "    predictions = model(batch.text).squeeze(1)\r\n",
        "    loss = criterion(predictions, batch.label)   # Calculate the loss\r\n",
        "    acc = model_accuracy(predictions, batch.label)\r\n",
        "    loss.backward()  # calculate the gradient of each parameter with loss.backward()\r\n",
        "    optimizer.step() # update the parameters using the gradients and optimizer algorithm\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    epoch_acc += acc.item()\r\n",
        "        \r\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muzzBFN3Ghx6"
      },
      "source": [
        "In eval function we do not want to update the parameters when evaluating.\r\n",
        "So, we don't need optimizer.zero_grad(), loss.backward() and optimizer.step()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9m0sENfUlmL"
      },
      "source": [
        "def eval(model, iterator, criterion):\r\n",
        "  epoch_loss = 0\r\n",
        "  epoch_acc = 0\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  with torch.no_grad(): \"\"\"No gradients are calculated on PyTorch operations inside the with no_grad() block. This causes less memory to be used and speeds up computation\"\"\"\r\n",
        "    for batch in iterator:\r\n",
        "      predictions = model(batch.text).squeeze(1)\r\n",
        "      loss = criterion(predictions, batch.label)\r\n",
        "      acc = model_accuracy(predictions, batch.label)\r\n",
        "\r\n",
        "      epoch_loss += loss.item()\r\n",
        "      epoch_acc += acc.item()\r\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)  "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpA6ixypWJPs",
        "outputId": "86c38ad8-044d-45aa-9821-11ccb087e13a"
      },
      "source": [
        "import time\r\n",
        "EPOCHS = 10\r\n",
        "opt_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start_time = time.time()\r\n",
        "  train_loss, train_acc = train(model, train_iter, optimizer, criterion)\r\n",
        "  valid_loss, valid_acc = eval(model, valid_iter, criterion)\r\n",
        "  end_time = time.time()\r\n",
        "  if valid_loss < opt_valid_loss:\r\n",
        "    opt_valid_loss = valid_loss\r\n",
        "    torch.save(model.state_dict(), 'RNN-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1}')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "\tTrain Loss: 0.693 | Train Acc: 0.50%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 0.50%\n",
            "Epoch: 2\n",
            "\tTrain Loss: 0.693 | Train Acc: 0.50%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 0.51%\n",
            "Epoch: 4\n",
            "\tTrain Loss: 0.693 | Train Acc: 0.50%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 0.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN542gsDHB1p"
      },
      "source": [
        "As we can see that the accuracy is poor. So, we need to improve the model by hypertuning it or to use different Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMbFlLXitZ-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca91002c-5130-43de-bd59-77171032f3b3"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/RNN-model.pt'))\r\n",
        "\r\n",
        "test_loss, test_acc = eval(model, test_iter, criterion)\r\n",
        "\r\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc:.2f}%')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.696 | Test Acc: 0.46%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}