{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlMYPe2VoSE-"
      },
      "source": [
        "import torch\r\n",
        "from torchtext import data, datasets\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "SEED = 1111"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jdY_wxaqaL_"
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy', batch_first=True)\r\n",
        "LABEL = data.LabelField(dtype=torch.float)\r\n",
        "\r\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL)\r\n",
        "\r\n",
        "train, valid = train.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp5f2CPTq-CT"
      },
      "source": [
        "MAX_VOCAB_SIZE = 20000\r\n",
        "\r\n",
        "TEXT.build_vocab(train,\r\n",
        "                 max_size = MAX_VOCAB_SIZE,\r\n",
        "                 vectors = 'glove.6B.100d',\r\n",
        "                 unk_init = torch.Tensor.normal_)\r\n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9DZDjabrP5I"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\r\n",
        "\r\n",
        "train_iter, valid_iter, test_iter = data.BucketIterator.splits(\r\n",
        "    (train, valid, test),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    device=device)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_szAtEvptyEO"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feSZdMuRxlh0"
      },
      "source": [
        "class CNN1d(nn.Module):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, \r\n",
        "               filter_size, output_dim, dropout, pad_idx):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\r\n",
        "    self.convs = nn.ModuleList([nn.Conv1d(in_channels = embedding_dim, \r\n",
        "                                          out_channels = n_filters,\r\n",
        "                                          kernel_size = fs) for fs in filter_size])\r\n",
        "    self.linear = nn.Linear(len(filter_size) * n_filters, output_dim)\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "\r\n",
        "  def forward(self, text):\r\n",
        "    embedded = self.embedding(text)\r\n",
        "    embedded = embedded.permute(0, 2, 1)\r\n",
        "    convd = [F.relu(conv(embedded)) for conv in self.convs]\r\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in convd]\r\n",
        "\r\n",
        "    cat = self.dropout(torch.cat(pooled, dim=1))\r\n",
        "\r\n",
        "    return self.linear(cat)\r\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wANWxpuLxn-R"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\r\n",
        "EMBEDDING_DIM = 100\r\n",
        "N_FILTERS = 100\r\n",
        "FILTER_SIZE = [3, 4, 5]\r\n",
        "OUTPUT_DIM = 1\r\n",
        "DROPOUT = 0.5\r\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\r\n",
        "\r\n",
        "model = CNN1d(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZE, OUTPUT_DIM, DROPOUT, PAD_IDX )"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWGB8Yq60DB5",
        "outputId": "6f8f4b30-fd67-4c81-8680-9fe974ca1df5"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\r\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5928, -1.6730, -1.4509,  ...,  0.7008,  0.9171, -1.0891],\n",
              "        [-0.1248, -0.0679, -0.1765,  ...,  1.1187, -1.8712, -0.4191],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-1.2715,  0.9957,  1.1696,  ...,  0.7124,  0.2630, -0.5472],\n",
              "        [-0.2365,  0.2716,  0.1552,  ..., -0.5834,  0.3832,  0.2393],\n",
              "        [ 0.1881,  0.3164,  0.6914,  ..., -0.5092,  0.7231,  0.6136]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct8gO27-0Xqn"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\r\n",
        "\r\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\r\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tIsqV-h0onA"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "\r\n",
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsKTdwTK1T73"
      },
      "source": [
        "def accuracy(predictions, y):\r\n",
        "  pred = torch.round(torch.sigmoid(predictions))\r\n",
        "  actual = (pred == y).float()\r\n",
        "  acc = actual.sum() / len(actual)\r\n",
        "  return acc"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QidD8_XE09wo"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\r\n",
        "  epoch_loss = 0\r\n",
        "  epoch_acc = 0\r\n",
        "  model.train()\r\n",
        "  for batch in iterator:\r\n",
        "    optimizer.zero_grad()\r\n",
        "    predictions = model(batch.text).squeeze(1)\r\n",
        "    loss = criterion(predictions, batch.label)\r\n",
        "    acc = accuracy(predictions, batch.label)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    epoch_acc += acc.item()\r\n",
        "\r\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8FUvuFW1wcC"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "  epoch_loss = 0\r\n",
        "  epoch_acc = 0\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    for batch in iterator:\r\n",
        "      predictions = model(batch.text).squeeze(1)\r\n",
        "      loss = criterion(predictions, batch.label)\r\n",
        "      acc = accuracy(predictions, batch.label)\r\n",
        "\r\n",
        "      epoch_loss += loss.item()\r\n",
        "      epoch_acc += acc.item()\r\n",
        "\r\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVAb2YMj2M6a",
        "outputId": "c8611235-dc9a-448f-a6f2-864c4f35bdd9"
      },
      "source": [
        "import time\r\n",
        "N_EPOCHS = 5\r\n",
        "\r\n",
        "opt_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "  start_time = time.time()\r\n",
        "  train_loss, train_acc = train(model, train_iter, optimizer, criterion)\r\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\r\n",
        "  end_time = time.time()\r\n",
        "\r\n",
        "  if valid_loss < opt_valid_loss:\r\n",
        "    opt_valid_loss = opt_valid_loss\r\n",
        "    torch.save(model.state_dict(), 'CNN1d_RNN_TC.pt')\r\n",
        "\r\n",
        "  print(f'Epoc: {epoch+1:02}')\r\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Accuracy: {train_acc:.3f}')\r\n",
        "  print(f'\\tValidation Loss: {valid_loss:.3f} | Validation Accuracy: {valid_acc:.3f}')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoc: 01\n",
            "\tTrain Loss: 0.027 | Train Accuracy: 0.992\n",
            "\tValidation Loss: 0.470 | Validation Accuracy: 0.870\n",
            "Epoc: 02\n",
            "\tTrain Loss: 0.023 | Train Accuracy: 0.993\n",
            "\tValidation Loss: 0.495 | Validation Accuracy: 0.872\n",
            "Epoc: 03\n",
            "\tTrain Loss: 0.019 | Train Accuracy: 0.995\n",
            "\tValidation Loss: 0.510 | Validation Accuracy: 0.872\n",
            "Epoc: 04\n",
            "\tTrain Loss: 0.015 | Train Accuracy: 0.996\n",
            "\tValidation Loss: 0.537 | Validation Accuracy: 0.876\n",
            "Epoc: 05\n",
            "\tTrain Loss: 0.014 | Train Accuracy: 0.996\n",
            "\tValidation Loss: 0.557 | Validation Accuracy: 0.872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDfOorE73NqX",
        "outputId": "94649527-1aa7-4caa-fa3a-56aec4bfe9a3"
      },
      "source": [
        "model.load_state_dict(torch.load('CNN1d_RNN_TC.pt'))\r\n",
        "test_loss, test_acc = evaluate(model, test_iter, criterion)\r\n",
        "\r\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Accuracy: {test_acc:.2f}')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.693 | Test Accuracy: 0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8BzCfK9Aswv"
      },
      "source": [
        "import spacy\r\n",
        "nlp = spacy.load('en')\r\n",
        "\r\n",
        "def predict_sentiment(model, text):\r\n",
        "  model.eval()\r\n",
        "  tokenized = [token.text for token in nlp.tokenizer(text)]\r\n",
        "  tokenized += ['<pad>'] * len(tokenized)\r\n",
        "  index = [TEXT.vocab.stoi[t] for t in tokenized]\r\n",
        "  tensor = torch.LongTensor(index).to(device)\r\n",
        "  tensor = tensor.unsqueeze(0)\r\n",
        "  prediction = torch.sigmoid(model(tensor))\r\n",
        "  return prediction.item()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn1izYWyBePk",
        "outputId": "c45884fc-6fb6-41c0-f322-40c99c8767d9"
      },
      "source": [
        "predict_sentiment(model, \"The weather is fine\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22681736946105957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grgYLw6vBqji",
        "outputId": "c4d5d605-357c-4683-f6f3-c0d1f72b778e"
      },
      "source": [
        "predict_sentiment(model, \"The weather is bad\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999772310256958"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_IYK4BiB3F6",
        "outputId": "4f187b02-c771-4837-a8e6-29572f8caca8"
      },
      "source": [
        "predict_sentiment(model, \"The weather is not good\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3321540951728821"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq3Hm5SGB5qS"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}