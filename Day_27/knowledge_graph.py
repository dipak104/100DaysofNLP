# -*- coding: utf-8 -*-
"""Knowledge Graph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VEc9vANoN-ZRlPvThHow3YnT4GeD88xX
"""

# Commented out IPython magic to ensure Python compatibility.
import spacy
import re
from spacy import displacy
from spacy.matcher import Matcher
from spacy.tokens import Span
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from tqdm import tqdm

pd.set_option('display.max_colwidth', 200)
# %matplotlib inline

nlp = spacy.load('en_core_web_sm')

df = pd.read_csv('/content/wiki_sentences_v2.csv')
print(df.shape)
df.head()

"""# Entities Extraction

The main idea is to go through a sentence and extract the subject and the object as and when they are encountered.
"""

def get_entities(sent):
  ent1 = ''
  ent2 = ''

  prev_dep = ''
  prev_text = ''

  prefix = ''
  modifier = ''

  for tok in nlp(sent):
    if tok.dep_ != 'punct':
      if tok.dep_ == 'compound':
        prefix = tok.text
        if prev_dep == 'compound':
          prefix = prev_text + " "+ tok.text

      if tok.dep_.endswith('mod') == True:
        modifier = tok.text
        if prev_dep == 'compound':
          modifier = prev_text + " "+ tok.text

      if tok.dep_.find('subj') == True:
        ent1 = modifier + " " + prefix + " " + tok.text
        prefix = ""
        modifier = ""
        prev_dep = ""
        prev_text = ""

      if tok.dep_.find('obj') == True:
        ent2 = modifier + " " + prefix + " " +tok.text

      prev_dep = tok.dep_
      prev_text = tok.text
  return [ent1.strip(), ent2.strip()]

get_entities("the film had 200 patents")

entity_pairs = []

for i in tqdm(df['sentence']):
  entity_pairs.append(get_entities(i))

"""# Relation Extraction"""

def get_relation(sent):
  doc = nlp(sent)

  matcher = Matcher(nlp.vocab)
  pattern = [{'DEP':'ROOT'},
             {'DEP':'prep', 'OP':'?'},
             {'DEP':'agent', 'OP':'?'},
             {'POS':'ADJ', 'OP':'?'}]
  
  matcher.add('matching', None, pattern)

  matches = matcher(doc)
  k = len(matches) - 1

  span = doc[matches[k][1]:matches[k][2]]

  return (span.text)

get_relation('John completed the task')

relations = [get_relation(i) for i in tqdm(df['sentence'])]

"""# Build a Knowledge Graph"""

source = [i[0] for i in entity_pairs]

target = [i[1] for i in entity_pairs]

kg = pd.DataFrame({'source':source, 'target':target,'edge':relations})

kg.head()

G = nx.from_pandas_edgelist(kg, 'source', 'target', edge_attr=True, create_using=nx.MultiDiGraph())

plt.figure(figsize=(12, 12))

pos = nx.spring_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
plt.show()

G = nx.from_pandas_edgelist(kg[kg['edge']=='composed by'], 'source','target', edge_attr=True, create_using=nx.MultiDiGraph())

plt.figure(figsize=(12, 12))
pos = nx.spring_layout(G, k=0.5)
nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap = plt.cm.Blues, pos=pos)
plt.show()

G = nx.from_pandas_edgelist(kg[kg['edge']=='written by'], 'source', 'target', edge_attr=True, create_using=nx.MultiDiGraph())

plt.figure(figsize=(12, 12))
pos = nx.spring_layout(G, k=0.5)
nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos=pos)
plt.show()

