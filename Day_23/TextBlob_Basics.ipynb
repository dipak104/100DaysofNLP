{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextBlob_Basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IGeOfpF8MSB",
        "outputId": "540a6734-9d00-4419-83fb-ee5955046c9a"
      },
      "source": [
        "# Downloadind the textblob corpora\r\n",
        "!python -m textblob.download_corpora"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaaLiYBp8Ow_",
        "outputId": "c8126e50-8b1a-4a48-b582-2f26d44be32a"
      },
      "source": [
        "# Tokenization\r\n",
        "\r\n",
        "from textblob import TextBlob\r\n",
        "\r\n",
        "blob = TextBlob('Tokenization refers to dividing text or a sentence into a sequence of tokens. which roughly correspond to words')\r\n",
        "\r\n",
        "print(blob.sentences)\r\n",
        "\r\n",
        "for words in blob.sentences[0].words:\r\n",
        "  print(words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Sentence(\"Tokenization refers to dividing text or a sentence into a sequence of tokens.\"), Sentence(\"which roughly correspond to words\")]\n",
            "Tokenization\n",
            "refers\n",
            "to\n",
            "dividing\n",
            "text\n",
            "or\n",
            "a\n",
            "sentence\n",
            "into\n",
            "a\n",
            "sequence\n",
            "of\n",
            "tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "farYADaT8k2-",
        "outputId": "99875bdb-a299-4f64-f27a-d5e78fa696b4"
      },
      "source": [
        "# Noun Phrase Extraction\r\n",
        "\r\n",
        "blob = TextBlob('Since we extracted the words in the previous section, instead of that we can just extract out the noun phrases from the textblob')\r\n",
        "for np in blob.noun_phrases:\r\n",
        "  print(np)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "previous section\n",
            "noun phrases\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhc1Dxv88wEA",
        "outputId": "67a8221e-e368-4ee8-e845-371c9c90f2d0"
      },
      "source": [
        "# Part of speech Tagging\r\n",
        "for words, tag in blob.tags:\r\n",
        "  print(words, tag)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Since IN\n",
            "we PRP\n",
            "extracted VBD\n",
            "the DT\n",
            "words NNS\n",
            "in IN\n",
            "the DT\n",
            "previous JJ\n",
            "section NN\n",
            "instead RB\n",
            "of IN\n",
            "that IN\n",
            "we PRP\n",
            "can MD\n",
            "just RB\n",
            "extract VB\n",
            "out RP\n",
            "the DT\n",
            "noun JJ\n",
            "phrases NNS\n",
            "from IN\n",
            "the DT\n",
            "textblob NN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI0DRdHI87zl",
        "outputId": "284330b2-9c9d-4b4d-dded-8d2cb54c9985"
      },
      "source": [
        "# Words Inflection and Lemmatization\r\n",
        "# Inflection is a process of word formation in which characters are added to \r\n",
        "# the base form of a word to express grammatical meanings\r\n",
        "\r\n",
        "blob = TextBlob('There is an accident on the street. It helps if someone call the ambulance')\r\n",
        "\r\n",
        "print(blob.sentences[1].words[1])\r\n",
        "print(blob.sentences[1].words[1].singularize())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "helps\n",
            "help\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g9g6EoeX9qJk",
        "outputId": "1db642c5-63be-43f1-9a25-778944d653db"
      },
      "source": [
        "#TextBlob library also offers an in-build object known as Word\r\n",
        "# We just need to create an object and apply the function to it.\r\n",
        "from textblob import Word\r\n",
        "w = Word('station')\r\n",
        "w.pluralize()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs1QmKSZ-p_T",
        "outputId": "97a34a86-dd4e-46d0-aa2d-f8c9106e64d4"
      },
      "source": [
        "for word, pos in blob.tags:\r\n",
        "  if pos == 'NN':\r\n",
        "    print(word.pluralize())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accidents\n",
            "streets\n",
            "someones\n",
            "ambulances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IDVQZEZU-9EO",
        "outputId": "13e959f2-91be-4ae1-97ce-5dae925f69a3"
      },
      "source": [
        "# Lemmatization\r\n",
        "w = Word('running')\r\n",
        "w.lemmatize('v')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'run'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hnUYKsl_Euq",
        "outputId": "08407a14-843c-4026-f36e-1c523e2904d4"
      },
      "source": [
        "# N-grams in Textblob\r\n",
        "\r\n",
        "for n in blob.ngrams(2):\r\n",
        "  print(n)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['There', 'is']\n",
            "['is', 'an']\n",
            "['an', 'accident']\n",
            "['accident', 'on']\n",
            "['on', 'the']\n",
            "['the', 'street']\n",
            "['street', 'It']\n",
            "['It', 'helps']\n",
            "['helps', 'if']\n",
            "['if', 'someone']\n",
            "['someone', 'call']\n",
            "['call', 'the']\n",
            "['the', 'ambulance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDE_AHCF_gMM"
      },
      "source": [
        "# Sentiment Analysis\r\n",
        "The sentiment function of textblob returns two properties, polarity, and subjectivity.\r\n",
        "Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A8uvwVF_ODQ",
        "outputId": "beeba22d-8531-435d-a34f-97fc9cde55dd"
      },
      "source": [
        "blob = TextBlob('This is amazing')\r\n",
        "print(blob)\r\n",
        "blob.sentiment\r\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is amazing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.6000000000000001, subjectivity=0.9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JdvGoR0_nw7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}